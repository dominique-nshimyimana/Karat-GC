{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of The %tensorflow_version magic",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominique-nshimyimana/Karat-GC/blob/master/Copy_of_The_tensorflow_version_magic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPDc8yQtVxk4"
      },
      "source": [
        "#TensorFlow versions in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ks9AkkCK98M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeWVBhf1VxlH",
        "outputId": "c6719a0f-840e-44d1-bbf5-2fc565d2326e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "e6c29792-3dba-4fc1-e7f7-f1122024b201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "mounted = '/drive'\n",
        "drive.mount(mounted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQaNEw6OKZn",
        "colab_type": "text"
      },
      "source": [
        "# NN state Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQXBfd9dOgPX",
        "colab_type": "code",
        "outputId": "f7566864-1746-48a8-e4ba-84456dd52686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class NeuralDynamics(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, state_size, action_size):\n",
        "\n",
        "        super(NeuralDynamics, self).__init__()\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        self.layer1 = tf.keras.layers.Dense(300, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=0.5)\n",
        "        self.layer2 = tf.keras.layers.Dense(300, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        '''\n",
        "        self.layer_mat1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.layer_mat2 = tf.keras.layers.Dense((self.state_size*(self.state_size + self.action_size)), kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        '''\n",
        "\n",
        "        self.layer_state1 = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "        self.layer_state2 = tf.keras.layers.Dense(self.state_size, kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
        "\n",
        "        self.known_inputs = False\n",
        "        self.training_step = 0\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "\n",
        "        state, action = inputs\n",
        "        if not self.known_inputs:\n",
        "            #model._set_inputs((tf.keras.Input(shape=state.get_shape()), tf.keras.Input(shape=action.get_shape())))\n",
        "            self.known_inputs = True\n",
        "\n",
        "        x = tf.concat((state, action), axis=1)\n",
        "        x = self.layer1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        '''\n",
        "        mat = self.layer_mat1(x)\n",
        "        mat = self.dropout(mat)\n",
        "        mat = self.layer_mat2(mat)\n",
        "        mat = tf.reshape(mat, shape=(tf.shape(mat)[0], self.state_size, self.state_size + self.action_size), name=\"Mat\")\n",
        "        '''\n",
        "        x = self.layer_state1(x)\n",
        "        x = self.dropout(x)\n",
        "        state = self.layer_state2(x)\n",
        "        return state#, mat\n",
        "\n",
        "    @tf.function\n",
        "    def linearize(self, state, action):\n",
        "        inputs = (tf.convert_to_tensor(state), tf.convert_to_tensor(action))\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(inputs)\n",
        "            state = self.call(inputs)\n",
        "        state_grad, action_grad = tape.gradient(state, inputs)\n",
        "        return state_grad\n",
        "\n",
        "\n",
        "decay=tf.keras.optimizers.schedules.ExponentialDecay(0.0004, 20000, 0.99)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=decay)\n",
        "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=decay)\n",
        "model = NeuralDynamics(6, 2)\n",
        "training_counter = 0\n",
        "\n",
        "\n",
        "def get_losses(s, a, s_):\n",
        "\n",
        "    #states_pred, mats_pred = model((s, a))\n",
        "    states_pred = model((s, a))\n",
        "    #predictions_mat = (mats_pred @ tf.concat((s, a), axis=1)[..., None])[..., 0]\n",
        "    #loss_mat = tf.reduce_mean(tf.keras.losses.mean_squared_error(s_, predictions_mat))\n",
        "    loss_state = tf.reduce_mean(tf.keras.losses.mean_squared_error(s_, states_pred))\n",
        "    loss = loss_state #+ loss_mat\n",
        "\n",
        "    #return loss, loss_mat, loss_state\n",
        "    return loss, loss_state\n",
        "\n",
        "\n",
        "def train_step(s, a, s_):\n",
        "    global training_counter\n",
        "    with tf.GradientTape() as tape:\n",
        "        #loss, loss_mat, loss_state = get_losses(s, a, s_)\n",
        "        loss,  loss_state = get_losses(s, a, s_)\n",
        "        if training_counter % 500 == 0:\n",
        "            print(\"The training loss for state is: {}\".format(loss_state))\n",
        "            #print(\"The training loss for mat is: {}\".format(loss_mat))\n",
        "            pass\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    training_counter += 1\n",
        "    #if loss < 0.5:\n",
        "    #    model.save(f'/home/kuba/NeuralModel/{loss:.2f}_{training_counter}/')\n",
        "\n",
        "def evaluate(s, a, s_):\n",
        "\n",
        "    #loss, loss_mat, loss_state = get_losses(s, a, s_)\n",
        "    loss, loss_state = get_losses(s, a, s_)\n",
        "    #return loss, loss_mat, loss_state\n",
        "    return loss, loss_state\n",
        "\n",
        "\n",
        "EPOCHS = 50\n",
        "data_dir = \"/drive/My Drive/neuronyte_logging\"\n",
        "data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) and \".directory\" not in f]\n",
        "\n",
        "cutoff_beginning = 300\n",
        "cutoff_end = 1000\n",
        "\n",
        "xs_states = []\n",
        "xs_actions = []\n",
        "ys = []\n",
        "\n",
        "for f in data_files:\n",
        "    print(f)\n",
        "    data = np.loadtxt(f, delimiter=', ', skiprows=1, dtype=np.float32)[cutoff_beginning:-cutoff_end, :]\n",
        "    x_states = [data[i, 1:-3] for i in range(len(data))]\n",
        "    x_actions = [data[i, -3:] for i in range(len(data))]\n",
        "    y = x_states[1:]\n",
        "    x_states, x_actions = x_states[:-1], x_actions[:-1]\n",
        "    xs_states += x_states\n",
        "    xs_actions += x_actions\n",
        "    ys += y\n",
        "\n",
        "xs_states = np.vstack(xs_states)\n",
        "xs_actions = np.vstack(xs_actions)\n",
        "ys = np.vstack(ys)\n",
        "brake_mask = xs_actions[:, 0] < xs_actions[:, 1]\n",
        "xs_actions[brake_mask, 0] = -xs_actions[brake_mask, 1]\n",
        "xs_actions = xs_actions[:, [0, 2]]\n",
        "\n",
        "xs_states_shape_before = xs_states.shape[0]\n",
        "xs_std_before = np.std(xs_states, axis=0)\n",
        "ys_std_before = np.std(ys, axis=0)\n",
        "\n",
        "inliers = ~np.any(abs(xs_states - np.mean(xs_states, axis=0)) >= 3*np.std(xs_states, axis=0), axis=1)\n",
        "xs_states = xs_states[inliers]\n",
        "xs_actions = xs_actions[inliers]\n",
        "ys = ys[inliers]\n",
        "\n",
        "inliers = ~np.any(abs(ys - np.mean(ys, axis=0)) >= 3*np.std(ys, axis=0), axis=1)\n",
        "xs_states = xs_states[inliers]\n",
        "xs_actions = xs_actions[inliers]\n",
        "ys = ys[inliers]\n",
        "\n",
        "print(\"Mean:\")\n",
        "print(np.mean(xs_states, axis=0))\n",
        "print(np.max(xs_states, axis=0))\n",
        "#xs_states -= np.mean(xs_states, axis=0)\n",
        "#xs_states /= np.std(xs_states, axis=0)\n",
        "\n",
        "print(\"Mean after normalization:\")\n",
        "print(np.mean(xs_states, axis=0))\n",
        "print(np.max(xs_states, axis=0))\n",
        "\n",
        "#ys -= np.mean(ys, axis=0)\n",
        "#ys /= np.std(ys, axis=0)\n",
        "\n",
        "xs_states_shape_after = xs_states.shape[0]\n",
        "xs_std_after = np.std(xs_states, axis=0)\n",
        "ys_std_after = np.std(ys, axis=0)\n",
        "\n",
        "print(f\"Dropped {xs_states_shape_before-xs_states_shape_after} outliers, size before {xs_states_shape_before}, size after {xs_states_shape_after}\")\n",
        "print(xs_std_before)\n",
        "print(xs_std_after)\n",
        "print(ys_std_before)\n",
        "print(ys_std_after)\n",
        "\n",
        "\n",
        "print(xs_states.shape, xs_actions.shape, ys.shape)\n",
        "\n",
        "x_states_train, x_states_test, x_actions_train, x_actions_test, y_train, y_test = train_test_split(xs_states, xs_actions, ys)\n",
        "print(x_states_train.shape, x_actions_train.shape, y_train.shape)\n",
        "print(x_states_test.shape, x_actions_test.shape, y_test.shape)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_states_train, x_actions_train, y_train)).shuffle(500000).batch(128)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_states_test, x_actions_test, y_test)).shuffle(500000).batch(16)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "    for x_state, x_action, y in train_ds:\n",
        "        train_step(x_state, x_action, y)\n",
        "\n",
        "    total_loss = 0\n",
        "    total_loss_mat = 0\n",
        "    total_loss_state = 0\n",
        "    i = 0\n",
        "    for x_state, x_action, y in test_ds:\n",
        "        i += 1\n",
        "        #loss, loss_mat, loss_state = evaluate(x_state, x_action, y)\n",
        "        loss, loss_state = evaluate(x_state, x_action, y)\n",
        "        total_loss += loss\n",
        "       # total_loss_mat += loss_mat\n",
        "        total_loss_state += loss_state\n",
        "        #print(model.linearize(x_state, x_action))\n",
        "        '''\n",
        "        if epoch > 10 and loss > 100:\n",
        "            print(\"High loss states:\")\n",
        "            for x, a, y_ in zip(x_state, x_action, y):\n",
        "                loss, loss_mat, loss_state = evaluate(tf.expand_dims(x, axis=0), tf.expand_dims(a, axis=0), tf.expand_dims(y_, axis=0))\n",
        "                print(\"----------------------------\")\n",
        "                print(f\"Total loss: {loss}, mat loss: {loss_mat}, state_loss: {loss_state}\")\n",
        "                print(\"State:\")\n",
        "                print(x)\n",
        "                print(\"Action:\")\n",
        "                print(a)\n",
        "                print(\"Result:\")\n",
        "                print(y_)\n",
        "        '''\n",
        "\n",
        "    print('\\033[94m' + f\"After {epoch} epochs the validation total loss is: {total_loss/i}\" + '\\033[0m')\n",
        "    print('\\033[94m' + f\"After {epoch} epochs the validation mat loss is: {total_loss_mat/i}\" + '\\033[0m')\n",
        "    print('\\033[94m' + f\"After {epoch} epochs the validation state loss is: {total_loss_state/i}\" + '\\033[0m')\n",
        "\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_states_train, x_actions_train, y_train)).shuffle(500000).batch(32)\n",
        "\n",
        "for x_states_train, x_actions_train, _ in train_ds:\n",
        "    print(\"predicitng\")\n",
        "    model.predict((x_states_train, x_actions_train))\n",
        "    break\n",
        "model.save(join(mounted, 'My Drive/NeuralModel/3/') )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585748620.316643\n",
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585745385.311904\n",
            "Mean:\n",
            "[-1.3224991e+02 -1.1697558e+02  1.3384195e-01  2.7793705e-01\n",
            " -1.5106058e-01 -3.9884944e-02]\n",
            "[10.6461  26.519    3.14158 26.3138  26.2639   9.53066]\n",
            "Mean after normalization:\n",
            "[-1.3224991e+02 -1.1697558e+02  1.3384195e-01  2.7793705e-01\n",
            " -1.5106058e-01 -3.9884944e-02]\n",
            "[10.6461  26.519    3.14158 26.3138  26.2639   9.53066]\n",
            "Dropped 3299 outliers, size before 1053425, size after 1050126\n",
            "[74.48583   50.47957    1.8485619 11.08395   10.294982  23.197948 ]\n",
            "[74.54682   50.47944    1.8488507 11.062421  10.309836   1.0919988]\n",
            "[74.48564   50.47938    1.8485597 11.083953  10.294984  23.197948 ]\n",
            "[74.54663   50.47921    1.8488514 11.062365  10.309894   1.0919839]\n",
            "(1050126, 6) (1050126, 2) (1050126, 6)\n",
            "(787594, 6) (787594, 2) (787594, 6)\n",
            "(262532, 6) (262532, 2) (262532, 6)\n",
            "Epoch 0/50\n",
            "The training loss for state is: 7183.607421875\n",
            "The training loss for state is: 0.09239158034324646\n",
            "The training loss for state is: 0.03215469419956207\n",
            "The training loss for state is: 0.08978724479675293\n",
            "The training loss for state is: 0.015571769326925278\n",
            "The training loss for state is: 0.01963276043534279\n",
            "The training loss for state is: 0.023898277431726456\n",
            "The training loss for state is: 0.019482441246509552\n",
            "The training loss for state is: 0.07598830759525299\n",
            "The training loss for state is: 0.008986846543848515\n",
            "The training loss for state is: 0.05096425116062164\n",
            "The training loss for state is: 0.45128366351127625\n",
            "The training loss for state is: 0.026262525469064713\n",
            "\u001b[94mAfter 0 epochs the validation total loss is: 0.1490839421749115\u001b[0m\n",
            "\u001b[94mAfter 0 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 0 epochs the validation state loss is: 0.1490839421749115\u001b[0m\n",
            "Epoch 1/50\n",
            "The training loss for state is: 0.33459997177124023\n",
            "The training loss for state is: 0.05210771784186363\n",
            "The training loss for state is: 0.020177101716399193\n",
            "The training loss for state is: 0.07052498310804367\n",
            "The training loss for state is: 0.25875532627105713\n",
            "The training loss for state is: 0.03629102185368538\n",
            "The training loss for state is: 0.03452548757195473\n",
            "The training loss for state is: 0.029512867331504822\n",
            "The training loss for state is: 0.07075764983892441\n",
            "The training loss for state is: 0.03039969876408577\n",
            "The training loss for state is: 0.1308283507823944\n",
            "The training loss for state is: 0.08853892982006073\n",
            "\u001b[94mAfter 1 epochs the validation total loss is: 0.04445160925388336\u001b[0m\n",
            "\u001b[94mAfter 1 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 1 epochs the validation state loss is: 0.04445160925388336\u001b[0m\n",
            "Epoch 2/50\n",
            "The training loss for state is: 0.017094971612095833\n",
            "The training loss for state is: 0.08774930238723755\n",
            "The training loss for state is: 0.025053925812244415\n",
            "The training loss for state is: 0.04226945713162422\n",
            "The training loss for state is: 0.06966084986925125\n",
            "The training loss for state is: 0.12495771050453186\n",
            "The training loss for state is: 0.1977251172065735\n",
            "The training loss for state is: 0.015395695343613625\n",
            "The training loss for state is: 0.05551646649837494\n",
            "The training loss for state is: 0.032551467418670654\n",
            "The training loss for state is: 0.0513712577521801\n",
            "The training loss for state is: 0.07362663000822067\n",
            "\u001b[94mAfter 2 epochs the validation total loss is: 0.04068369045853615\u001b[0m\n",
            "\u001b[94mAfter 2 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 2 epochs the validation state loss is: 0.04068369045853615\u001b[0m\n",
            "Epoch 3/50\n",
            "The training loss for state is: 0.03713018074631691\n",
            "The training loss for state is: 0.01512871216982603\n",
            "The training loss for state is: 0.013109554536640644\n",
            "The training loss for state is: 0.030577708035707474\n",
            "The training loss for state is: 0.04006093367934227\n",
            "The training loss for state is: 0.06507577747106552\n",
            "The training loss for state is: 0.046274133026599884\n",
            "The training loss for state is: 0.043199941515922546\n",
            "The training loss for state is: 0.013739578425884247\n",
            "The training loss for state is: 0.031863316893577576\n",
            "The training loss for state is: 0.17118380963802338\n",
            "The training loss for state is: 0.11601430177688599\n",
            "The training loss for state is: 0.09567517042160034\n",
            "\u001b[94mAfter 3 epochs the validation total loss is: 0.06936056166887283\u001b[0m\n",
            "\u001b[94mAfter 3 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 3 epochs the validation state loss is: 0.06936056166887283\u001b[0m\n",
            "Epoch 4/50\n",
            "The training loss for state is: 0.03300754725933075\n",
            "The training loss for state is: 0.01891724020242691\n",
            "The training loss for state is: 0.07953118532896042\n",
            "The training loss for state is: 0.04975143447518349\n",
            "The training loss for state is: 0.032547831535339355\n",
            "The training loss for state is: 0.015896473079919815\n",
            "The training loss for state is: 0.0467461422085762\n",
            "The training loss for state is: 0.01565021649003029\n",
            "The training loss for state is: 0.010964451357722282\n",
            "The training loss for state is: 0.021983366459608078\n",
            "The training loss for state is: 0.061801984906196594\n",
            "The training loss for state is: 0.013445015996694565\n",
            "\u001b[94mAfter 4 epochs the validation total loss is: 0.01896258443593979\u001b[0m\n",
            "\u001b[94mAfter 4 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 4 epochs the validation state loss is: 0.01896258443593979\u001b[0m\n",
            "Epoch 5/50\n",
            "The training loss for state is: 0.02460765838623047\n",
            "The training loss for state is: 0.12681221961975098\n",
            "The training loss for state is: 0.05732421949505806\n",
            "The training loss for state is: 0.02743900567293167\n",
            "The training loss for state is: 0.30789369344711304\n",
            "The training loss for state is: 0.4653380811214447\n",
            "The training loss for state is: 0.023578844964504242\n",
            "The training loss for state is: 0.011806762777268887\n",
            "The training loss for state is: 0.014974129386246204\n",
            "The training loss for state is: 0.011214392259716988\n",
            "The training loss for state is: 0.06157354265451431\n",
            "The training loss for state is: 0.01898910105228424\n",
            "\u001b[94mAfter 5 epochs the validation total loss is: 0.056465450674295425\u001b[0m\n",
            "\u001b[94mAfter 5 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 5 epochs the validation state loss is: 0.056465450674295425\u001b[0m\n",
            "Epoch 6/50\n",
            "The training loss for state is: 0.018554065376520157\n",
            "The training loss for state is: 0.02086731791496277\n",
            "The training loss for state is: 0.02390877902507782\n",
            "The training loss for state is: 0.018620194867253304\n",
            "The training loss for state is: 0.012811006978154182\n",
            "The training loss for state is: 0.010463797487318516\n",
            "The training loss for state is: 0.01896735653281212\n",
            "The training loss for state is: 0.00771890627220273\n",
            "The training loss for state is: 0.01898893527686596\n",
            "The training loss for state is: 0.009002594277262688\n",
            "The training loss for state is: 0.01142458338290453\n",
            "The training loss for state is: 0.09393708407878876\n",
            "The training loss for state is: 0.0337684340775013\n",
            "\u001b[94mAfter 6 epochs the validation total loss is: 0.03217010572552681\u001b[0m\n",
            "\u001b[94mAfter 6 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 6 epochs the validation state loss is: 0.03217010572552681\u001b[0m\n",
            "Epoch 7/50\n",
            "The training loss for state is: 0.030140604823827744\n",
            "The training loss for state is: 0.022699978202581406\n",
            "The training loss for state is: 0.012236982583999634\n",
            "The training loss for state is: 0.00855269469320774\n",
            "The training loss for state is: 0.008539015427231789\n",
            "The training loss for state is: 0.016060421243309975\n",
            "The training loss for state is: 0.012152283452451229\n",
            "The training loss for state is: 0.040400490164756775\n",
            "The training loss for state is: 0.016027512028813362\n",
            "The training loss for state is: 0.0217535812407732\n",
            "The training loss for state is: 0.00603130180388689\n",
            "The training loss for state is: 0.021518897265195847\n",
            "\u001b[94mAfter 7 epochs the validation total loss is: 0.021876707673072815\u001b[0m\n",
            "\u001b[94mAfter 7 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 7 epochs the validation state loss is: 0.021876707673072815\u001b[0m\n",
            "Epoch 8/50\n",
            "The training loss for state is: 0.007419729605317116\n",
            "The training loss for state is: 0.06865422427654266\n",
            "The training loss for state is: 0.023772630840539932\n",
            "The training loss for state is: 0.008495396003127098\n",
            "The training loss for state is: 0.016009114682674408\n",
            "The training loss for state is: 0.02309427410364151\n",
            "The training loss for state is: 0.03570021688938141\n",
            "The training loss for state is: 0.031947508454322815\n",
            "The training loss for state is: 0.01151634007692337\n",
            "The training loss for state is: 0.04326638951897621\n",
            "The training loss for state is: 0.01414685882627964\n",
            "The training loss for state is: 0.023660223931074142\n",
            "\u001b[94mAfter 8 epochs the validation total loss is: 0.035518549382686615\u001b[0m\n",
            "\u001b[94mAfter 8 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 8 epochs the validation state loss is: 0.035518549382686615\u001b[0m\n",
            "Epoch 9/50\n",
            "The training loss for state is: 0.020044993609189987\n",
            "The training loss for state is: 0.019984997808933258\n",
            "The training loss for state is: 0.019853487610816956\n",
            "The training loss for state is: 0.07028133422136307\n",
            "The training loss for state is: 0.012685654684901237\n",
            "The training loss for state is: 0.008550127036869526\n",
            "The training loss for state is: 0.024299034848809242\n",
            "The training loss for state is: 0.013231122866272926\n",
            "The training loss for state is: 0.02610217034816742\n",
            "The training loss for state is: 0.06156652048230171\n",
            "The training loss for state is: 0.009993313811719418\n",
            "The training loss for state is: 0.008334854617714882\n",
            "The training loss for state is: 0.01437748596072197\n",
            "\u001b[94mAfter 9 epochs the validation total loss is: 0.028410371392965317\u001b[0m\n",
            "\u001b[94mAfter 9 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 9 epochs the validation state loss is: 0.028410371392965317\u001b[0m\n",
            "Epoch 10/50\n",
            "The training loss for state is: 0.055034469813108444\n",
            "The training loss for state is: 0.021235831081867218\n",
            "The training loss for state is: 0.008877141401171684\n",
            "The training loss for state is: 0.012977512553334236\n",
            "The training loss for state is: 0.1216377466917038\n",
            "The training loss for state is: 0.014957338571548462\n",
            "The training loss for state is: 0.009381706826388836\n",
            "The training loss for state is: 0.014174528419971466\n",
            "The training loss for state is: 0.033789683133363724\n",
            "The training loss for state is: 0.1029716432094574\n",
            "The training loss for state is: 0.027650371193885803\n",
            "The training loss for state is: 0.04194996878504753\n",
            "\u001b[94mAfter 10 epochs the validation total loss is: 0.04756024852395058\u001b[0m\n",
            "\u001b[94mAfter 10 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 10 epochs the validation state loss is: 0.04756024852395058\u001b[0m\n",
            "Epoch 11/50\n",
            "The training loss for state is: 0.013280048966407776\n",
            "The training loss for state is: 0.008484328165650368\n",
            "The training loss for state is: 0.020432056859135628\n",
            "The training loss for state is: 0.031217556446790695\n",
            "The training loss for state is: 0.012173976749181747\n",
            "The training loss for state is: 0.030485298484563828\n",
            "The training loss for state is: 0.022668199613690376\n",
            "The training loss for state is: 0.019793560728430748\n",
            "The training loss for state is: 0.012600798159837723\n",
            "The training loss for state is: 0.050859659910202026\n",
            "The training loss for state is: 0.01510431244969368\n",
            "The training loss for state is: 0.02610422484576702\n",
            "\u001b[94mAfter 11 epochs the validation total loss is: 0.02923121117055416\u001b[0m\n",
            "\u001b[94mAfter 11 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 11 epochs the validation state loss is: 0.02923121117055416\u001b[0m\n",
            "Epoch 12/50\n",
            "The training loss for state is: 0.01123836264014244\n",
            "The training loss for state is: 0.035231463611125946\n",
            "The training loss for state is: 0.009958324022591114\n",
            "The training loss for state is: 0.009818151593208313\n",
            "The training loss for state is: 0.025928214192390442\n",
            "The training loss for state is: 0.008750110864639282\n",
            "The training loss for state is: 0.006621296517550945\n",
            "The training loss for state is: 0.008471036329865456\n",
            "The training loss for state is: 0.036372799426317215\n",
            "The training loss for state is: 0.008197246119379997\n",
            "The training loss for state is: 0.01131189614534378\n",
            "The training loss for state is: 0.00960822869092226\n",
            "The training loss for state is: 0.009143782779574394\n",
            "\u001b[94mAfter 12 epochs the validation total loss is: 0.049050476402044296\u001b[0m\n",
            "\u001b[94mAfter 12 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 12 epochs the validation state loss is: 0.049050476402044296\u001b[0m\n",
            "Epoch 13/50\n",
            "The training loss for state is: 0.019979186356067657\n",
            "The training loss for state is: 0.05760269612073898\n",
            "The training loss for state is: 0.010188780725002289\n",
            "The training loss for state is: 0.023092778399586678\n",
            "The training loss for state is: 0.016825556755065918\n",
            "The training loss for state is: 0.031576089560985565\n",
            "The training loss for state is: 0.020213257521390915\n",
            "The training loss for state is: 0.018841275945305824\n",
            "The training loss for state is: 0.019844621419906616\n",
            "The training loss for state is: 0.039374783635139465\n",
            "The training loss for state is: 0.024519655853509903\n",
            "The training loss for state is: 0.0697336420416832\n",
            "\u001b[94mAfter 13 epochs the validation total loss is: 0.04848397150635719\u001b[0m\n",
            "\u001b[94mAfter 13 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 13 epochs the validation state loss is: 0.04848397150635719\u001b[0m\n",
            "Epoch 14/50\n",
            "The training loss for state is: 0.06752884387969971\n",
            "The training loss for state is: 0.014470805414021015\n",
            "The training loss for state is: 0.01873699761927128\n",
            "The training loss for state is: 0.07879190146923065\n",
            "The training loss for state is: 0.01790674217045307\n",
            "The training loss for state is: 0.010026158764958382\n",
            "The training loss for state is: 0.008395816199481487\n",
            "The training loss for state is: 0.006708033382892609\n",
            "The training loss for state is: 0.005705227144062519\n",
            "The training loss for state is: 0.02778276987373829\n",
            "The training loss for state is: 0.011536093428730965\n",
            "The training loss for state is: 0.0072430758737027645\n",
            "\u001b[94mAfter 14 epochs the validation total loss is: 0.030070219188928604\u001b[0m\n",
            "\u001b[94mAfter 14 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 14 epochs the validation state loss is: 0.030070219188928604\u001b[0m\n",
            "Epoch 15/50\n",
            "The training loss for state is: 0.13177454471588135\n",
            "The training loss for state is: 0.009838512167334557\n",
            "The training loss for state is: 0.023964017629623413\n",
            "The training loss for state is: 0.014632631093263626\n",
            "The training loss for state is: 0.010519752278923988\n",
            "The training loss for state is: 0.025667710229754448\n",
            "The training loss for state is: 0.04164921119809151\n",
            "The training loss for state is: 0.01809540204703808\n",
            "The training loss for state is: 0.018676340579986572\n",
            "The training loss for state is: 0.01318705640733242\n",
            "The training loss for state is: 0.019748171791434288\n",
            "The training loss for state is: 0.29207831621170044\n",
            "\u001b[94mAfter 15 epochs the validation total loss is: 0.032069411128759384\u001b[0m\n",
            "\u001b[94mAfter 15 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 15 epochs the validation state loss is: 0.032069411128759384\u001b[0m\n",
            "Epoch 16/50\n",
            "The training loss for state is: 0.011871270835399628\n",
            "The training loss for state is: 0.014535084366798401\n",
            "The training loss for state is: 0.05978430062532425\n",
            "The training loss for state is: 0.015432164072990417\n",
            "The training loss for state is: 0.05901686102151871\n",
            "The training loss for state is: 0.05729633942246437\n",
            "The training loss for state is: 0.01190248504281044\n",
            "The training loss for state is: 0.029832512140274048\n",
            "The training loss for state is: 0.019214577972888947\n",
            "The training loss for state is: 0.019442882388830185\n",
            "The training loss for state is: 0.040531404316425323\n",
            "The training loss for state is: 0.05578767880797386\n",
            "The training loss for state is: 0.00996672734618187\n",
            "\u001b[94mAfter 16 epochs the validation total loss is: 0.03733335807919502\u001b[0m\n",
            "\u001b[94mAfter 16 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 16 epochs the validation state loss is: 0.03733335807919502\u001b[0m\n",
            "Epoch 17/50\n",
            "The training loss for state is: 0.059253986924886703\n",
            "The training loss for state is: 0.03127481788396835\n",
            "The training loss for state is: 0.078695148229599\n",
            "The training loss for state is: 0.056599587202072144\n",
            "The training loss for state is: 0.05717501416802406\n",
            "The training loss for state is: 0.05719343572854996\n",
            "The training loss for state is: 0.01249096728861332\n",
            "The training loss for state is: 0.05729921907186508\n",
            "The training loss for state is: 0.04206423833966255\n",
            "The training loss for state is: 0.010128559544682503\n",
            "The training loss for state is: 0.014010606333613396\n",
            "The training loss for state is: 0.020280972123146057\n",
            "\u001b[94mAfter 17 epochs the validation total loss is: 0.06624717265367508\u001b[0m\n",
            "\u001b[94mAfter 17 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 17 epochs the validation state loss is: 0.06624717265367508\u001b[0m\n",
            "Epoch 18/50\n",
            "The training loss for state is: 0.012197264470160007\n",
            "The training loss for state is: 0.02734547108411789\n",
            "The training loss for state is: 0.03917727991938591\n",
            "The training loss for state is: 0.009989675134420395\n",
            "The training loss for state is: 0.06297321617603302\n",
            "The training loss for state is: 0.009097054600715637\n",
            "The training loss for state is: 0.056210678070783615\n",
            "The training loss for state is: 0.030280988663434982\n",
            "The training loss for state is: 0.022992566227912903\n",
            "The training loss for state is: 0.022583838552236557\n",
            "The training loss for state is: 0.009276965633034706\n",
            "The training loss for state is: 0.008438876830041409\n",
            "\u001b[94mAfter 18 epochs the validation total loss is: 0.013815661892294884\u001b[0m\n",
            "\u001b[94mAfter 18 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 18 epochs the validation state loss is: 0.013815661892294884\u001b[0m\n",
            "Epoch 19/50\n",
            "The training loss for state is: 0.012041304260492325\n",
            "The training loss for state is: 0.014388351701200008\n",
            "The training loss for state is: 0.006845527794212103\n",
            "The training loss for state is: 0.006157346535474062\n",
            "The training loss for state is: 0.008484945632517338\n",
            "The training loss for state is: 0.014133747667074203\n",
            "The training loss for state is: 0.00923006609082222\n",
            "The training loss for state is: 0.011726755648851395\n",
            "The training loss for state is: 0.005425550974905491\n",
            "The training loss for state is: 0.006049697287380695\n",
            "The training loss for state is: 0.010064661502838135\n",
            "The training loss for state is: 0.015023207291960716\n",
            "The training loss for state is: 0.01135033369064331\n",
            "\u001b[94mAfter 19 epochs the validation total loss is: 0.02896355465054512\u001b[0m\n",
            "\u001b[94mAfter 19 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 19 epochs the validation state loss is: 0.02896355465054512\u001b[0m\n",
            "Epoch 20/50\n",
            "The training loss for state is: 0.019472869113087654\n",
            "The training loss for state is: 0.01463303156197071\n",
            "The training loss for state is: 0.011203623376786709\n",
            "The training loss for state is: 0.009222269989550114\n",
            "The training loss for state is: 0.05977227911353111\n",
            "The training loss for state is: 0.03869660198688507\n",
            "The training loss for state is: 0.009091075509786606\n",
            "The training loss for state is: 0.011865382082760334\n",
            "The training loss for state is: 0.014029139652848244\n",
            "The training loss for state is: 0.007860609330236912\n",
            "The training loss for state is: 0.020158980041742325\n",
            "The training loss for state is: 0.00980529747903347\n",
            "\u001b[94mAfter 20 epochs the validation total loss is: 0.025881798937916756\u001b[0m\n",
            "\u001b[94mAfter 20 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 20 epochs the validation state loss is: 0.025881798937916756\u001b[0m\n",
            "Epoch 21/50\n",
            "The training loss for state is: 0.018573004752397537\n",
            "The training loss for state is: 0.028099827468395233\n",
            "The training loss for state is: 0.01994987577199936\n",
            "The training loss for state is: 0.0065278103575110435\n",
            "The training loss for state is: 0.011907128617167473\n",
            "The training loss for state is: 0.009863211773335934\n",
            "The training loss for state is: 0.007667113095521927\n",
            "The training loss for state is: 0.005816423799842596\n",
            "The training loss for state is: 0.00949803926050663\n",
            "The training loss for state is: 0.009592017158865929\n",
            "The training loss for state is: 0.02913002297282219\n",
            "The training loss for state is: 0.008497951552271843\n",
            "\u001b[94mAfter 21 epochs the validation total loss is: 0.13238660991191864\u001b[0m\n",
            "\u001b[94mAfter 21 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 21 epochs the validation state loss is: 0.13238660991191864\u001b[0m\n",
            "Epoch 22/50\n",
            "The training loss for state is: 0.011155972257256508\n",
            "The training loss for state is: 0.016734488308429718\n",
            "The training loss for state is: 0.055902060121297836\n",
            "The training loss for state is: 0.029238959774374962\n",
            "The training loss for state is: 0.059933874756097794\n",
            "The training loss for state is: 0.007852057926356792\n",
            "The training loss for state is: 0.013743974268436432\n",
            "The training loss for state is: 0.009370940737426281\n",
            "The training loss for state is: 0.006307041738182306\n",
            "The training loss for state is: 0.008739061653614044\n",
            "The training loss for state is: 0.006763426121324301\n",
            "The training loss for state is: 0.03454073891043663\n",
            "The training loss for state is: 0.009522920474410057\n",
            "\u001b[94mAfter 22 epochs the validation total loss is: 0.018371853977441788\u001b[0m\n",
            "\u001b[94mAfter 22 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 22 epochs the validation state loss is: 0.018371853977441788\u001b[0m\n",
            "Epoch 23/50\n",
            "The training loss for state is: 0.011327100917696953\n",
            "The training loss for state is: 0.022674139589071274\n",
            "The training loss for state is: 0.012561559677124023\n",
            "The training loss for state is: 0.014113066717982292\n",
            "The training loss for state is: 0.010657135397195816\n",
            "The training loss for state is: 0.013057897798717022\n",
            "The training loss for state is: 0.015895837917923927\n",
            "The training loss for state is: 0.05879140645265579\n",
            "The training loss for state is: 0.008997919037938118\n",
            "The training loss for state is: 0.0160004161298275\n",
            "The training loss for state is: 0.024209048599004745\n",
            "The training loss for state is: 0.011593302711844444\n",
            "\u001b[94mAfter 23 epochs the validation total loss is: 0.02132752165198326\u001b[0m\n",
            "\u001b[94mAfter 23 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 23 epochs the validation state loss is: 0.02132752165198326\u001b[0m\n",
            "Epoch 24/50\n",
            "The training loss for state is: 0.05517124757170677\n",
            "The training loss for state is: 0.011638923548161983\n",
            "The training loss for state is: 0.007331224624067545\n",
            "The training loss for state is: 0.011371112428605556\n",
            "The training loss for state is: 0.0054098982363939285\n",
            "The training loss for state is: 0.01336422935128212\n",
            "The training loss for state is: 0.056309085339307785\n",
            "The training loss for state is: 0.06386269629001617\n",
            "The training loss for state is: 0.0117895333096385\n",
            "The training loss for state is: 0.014130452647805214\n",
            "The training loss for state is: 0.005439583212137222\n",
            "The training loss for state is: 0.03511754795908928\n",
            "\u001b[94mAfter 24 epochs the validation total loss is: 0.015806037932634354\u001b[0m\n",
            "\u001b[94mAfter 24 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 24 epochs the validation state loss is: 0.015806037932634354\u001b[0m\n",
            "Epoch 25/50\n",
            "The training loss for state is: 0.011431539431214333\n",
            "The training loss for state is: 0.014015935361385345\n",
            "The training loss for state is: 0.007933774963021278\n",
            "The training loss for state is: 0.02097831480205059\n",
            "The training loss for state is: 0.01097157597541809\n",
            "The training loss for state is: 0.0370454303920269\n",
            "The training loss for state is: 0.01107107661664486\n",
            "The training loss for state is: 0.007683193311095238\n",
            "The training loss for state is: 0.012352305464446545\n",
            "The training loss for state is: 0.008791673928499222\n",
            "The training loss for state is: 0.027073238044977188\n",
            "The training loss for state is: 0.006962112616747618\n",
            "The training loss for state is: 0.009317142888903618\n",
            "\u001b[94mAfter 25 epochs the validation total loss is: 0.04560219496488571\u001b[0m\n",
            "\u001b[94mAfter 25 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 25 epochs the validation state loss is: 0.04560219496488571\u001b[0m\n",
            "Epoch 26/50\n",
            "The training loss for state is: 0.03099783882498741\n",
            "The training loss for state is: 0.009087814949452877\n",
            "The training loss for state is: 0.03293856605887413\n",
            "The training loss for state is: 0.010583263821899891\n",
            "The training loss for state is: 0.016015952453017235\n",
            "The training loss for state is: 0.01979885809123516\n",
            "The training loss for state is: 0.011291556060314178\n",
            "The training loss for state is: 0.006345929577946663\n",
            "The training loss for state is: 0.010494685731828213\n",
            "The training loss for state is: 0.03232771158218384\n",
            "The training loss for state is: 0.017033640295267105\n",
            "The training loss for state is: 0.0077940234914422035\n",
            "\u001b[94mAfter 26 epochs the validation total loss is: 0.0296245776116848\u001b[0m\n",
            "\u001b[94mAfter 26 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 26 epochs the validation state loss is: 0.0296245776116848\u001b[0m\n",
            "Epoch 27/50\n",
            "The training loss for state is: 0.020337451249361038\n",
            "The training loss for state is: 0.01863284967839718\n",
            "The training loss for state is: 0.055140137672424316\n",
            "The training loss for state is: 0.009471461176872253\n",
            "The training loss for state is: 0.03619791567325592\n",
            "The training loss for state is: 0.01829582452774048\n",
            "The training loss for state is: 0.0052676452323794365\n",
            "The training loss for state is: 0.007456840015947819\n",
            "The training loss for state is: 0.018578754737973213\n",
            "The training loss for state is: 0.010559526272118092\n",
            "The training loss for state is: 0.05973003804683685\n",
            "The training loss for state is: 0.007976183667778969\n",
            "\u001b[94mAfter 27 epochs the validation total loss is: 0.04040741175413132\u001b[0m\n",
            "\u001b[94mAfter 27 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 27 epochs the validation state loss is: 0.04040741175413132\u001b[0m\n",
            "Epoch 28/50\n",
            "The training loss for state is: 0.02293848991394043\n",
            "The training loss for state is: 0.01761411316692829\n",
            "The training loss for state is: 0.01098786760121584\n",
            "The training loss for state is: 0.019368456676602364\n",
            "The training loss for state is: 0.05308719724416733\n",
            "The training loss for state is: 0.010884786024689674\n",
            "The training loss for state is: 0.006393308751285076\n",
            "The training loss for state is: 0.014390682801604271\n",
            "The training loss for state is: 0.006523121148347855\n",
            "The training loss for state is: 0.009310147725045681\n",
            "The training loss for state is: 0.05843936651945114\n",
            "The training loss for state is: 0.025771530345082283\n",
            "\u001b[94mAfter 28 epochs the validation total loss is: 0.022827373817563057\u001b[0m\n",
            "\u001b[94mAfter 28 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 28 epochs the validation state loss is: 0.022827373817563057\u001b[0m\n",
            "Epoch 29/50\n",
            "The training loss for state is: 0.009252668358385563\n",
            "The training loss for state is: 0.06236940249800682\n",
            "The training loss for state is: 0.005716116167604923\n",
            "The training loss for state is: 0.004849590361118317\n",
            "The training loss for state is: 0.005695781670510769\n",
            "The training loss for state is: 0.008984997868537903\n",
            "The training loss for state is: 0.008346278220415115\n",
            "The training loss for state is: 0.010204765945672989\n",
            "The training loss for state is: 0.010483941994607449\n",
            "The training loss for state is: 0.010061606764793396\n",
            "The training loss for state is: 0.031749412417411804\n",
            "The training loss for state is: 0.012200647965073586\n",
            "The training loss for state is: 0.012413924559950829\n",
            "\u001b[94mAfter 29 epochs the validation total loss is: 0.05140231177210808\u001b[0m\n",
            "\u001b[94mAfter 29 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 29 epochs the validation state loss is: 0.05140231177210808\u001b[0m\n",
            "Epoch 30/50\n",
            "The training loss for state is: 0.016347624361515045\n",
            "The training loss for state is: 0.01215836126357317\n",
            "The training loss for state is: 0.05668237432837486\n",
            "The training loss for state is: 0.0076494840905070305\n",
            "The training loss for state is: 0.01646852120757103\n",
            "The training loss for state is: 0.013376169838011265\n",
            "The training loss for state is: 0.007487420924007893\n",
            "The training loss for state is: 0.014934787526726723\n",
            "The training loss for state is: 0.0688418596982956\n",
            "The training loss for state is: 0.03202041611075401\n",
            "The training loss for state is: 0.025383245199918747\n",
            "The training loss for state is: 0.01817288063466549\n",
            "\u001b[94mAfter 30 epochs the validation total loss is: 0.028720391914248466\u001b[0m\n",
            "\u001b[94mAfter 30 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 30 epochs the validation state loss is: 0.028720391914248466\u001b[0m\n",
            "Epoch 31/50\n",
            "The training loss for state is: 0.007771700620651245\n",
            "The training loss for state is: 0.029054909944534302\n",
            "The training loss for state is: 0.062067385762929916\n",
            "The training loss for state is: 0.006079427897930145\n",
            "The training loss for state is: 0.016933469101786613\n",
            "The training loss for state is: 0.017866559326648712\n",
            "The training loss for state is: 0.007557436358183622\n",
            "The training loss for state is: 0.009944219142198563\n",
            "The training loss for state is: 0.01114568393677473\n",
            "The training loss for state is: 0.006255729123950005\n",
            "The training loss for state is: 0.01264699175953865\n",
            "The training loss for state is: 0.025537662208080292\n",
            "\u001b[94mAfter 31 epochs the validation total loss is: 0.03344912827014923\u001b[0m\n",
            "\u001b[94mAfter 31 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 31 epochs the validation state loss is: 0.03344912827014923\u001b[0m\n",
            "Epoch 32/50\n",
            "The training loss for state is: 0.009708010591566563\n",
            "The training loss for state is: 0.04323481768369675\n",
            "The training loss for state is: 0.05600288510322571\n",
            "The training loss for state is: 0.008318306878209114\n",
            "The training loss for state is: 0.014148615300655365\n",
            "The training loss for state is: 0.013553031720221043\n",
            "The training loss for state is: 0.024694785475730896\n",
            "The training loss for state is: 0.005805507302284241\n",
            "The training loss for state is: 0.05755097419023514\n",
            "The training loss for state is: 0.013966602273285389\n",
            "The training loss for state is: 0.05957283824682236\n",
            "The training loss for state is: 0.031150391325354576\n",
            "The training loss for state is: 0.01515954453498125\n",
            "\u001b[94mAfter 32 epochs the validation total loss is: 0.017840882763266563\u001b[0m\n",
            "\u001b[94mAfter 32 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 32 epochs the validation state loss is: 0.017840882763266563\u001b[0m\n",
            "Epoch 33/50\n",
            "The training loss for state is: 0.013129404745995998\n",
            "The training loss for state is: 0.010304849594831467\n",
            "The training loss for state is: 0.01065237820148468\n",
            "The training loss for state is: 0.007580920122563839\n",
            "The training loss for state is: 0.010683205910027027\n",
            "The training loss for state is: 0.009747164323925972\n",
            "The training loss for state is: 0.11859594285488129\n",
            "The training loss for state is: 0.01953626424074173\n",
            "The training loss for state is: 0.013590025715529919\n",
            "The training loss for state is: 0.010867036879062653\n",
            "The training loss for state is: 0.03684965521097183\n",
            "The training loss for state is: 0.056412942707538605\n",
            "\u001b[94mAfter 33 epochs the validation total loss is: 0.015004465356469154\u001b[0m\n",
            "\u001b[94mAfter 33 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 33 epochs the validation state loss is: 0.015004465356469154\u001b[0m\n",
            "Epoch 34/50\n",
            "The training loss for state is: 0.06254027038812637\n",
            "The training loss for state is: 0.009219568222761154\n",
            "The training loss for state is: 0.008170882239937782\n",
            "The training loss for state is: 0.033786043524742126\n",
            "The training loss for state is: 0.02378668263554573\n",
            "The training loss for state is: 0.05424726381897926\n",
            "The training loss for state is: 0.016569126397371292\n",
            "The training loss for state is: 0.011576471850275993\n",
            "The training loss for state is: 0.012440581806004047\n",
            "The training loss for state is: 0.02462758496403694\n",
            "The training loss for state is: 0.06307650357484818\n",
            "The training loss for state is: 0.009305876679718494\n",
            "\u001b[94mAfter 34 epochs the validation total loss is: 0.020773088559508324\u001b[0m\n",
            "\u001b[94mAfter 34 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 34 epochs the validation state loss is: 0.020773088559508324\u001b[0m\n",
            "Epoch 35/50\n",
            "The training loss for state is: 0.057875409722328186\n",
            "The training loss for state is: 0.005923321004956961\n",
            "The training loss for state is: 0.009689592756330967\n",
            "The training loss for state is: 0.016226885840296745\n",
            "The training loss for state is: 0.01315417792648077\n",
            "The training loss for state is: 0.006850932724773884\n",
            "The training loss for state is: 0.0695684626698494\n",
            "The training loss for state is: 0.008632853627204895\n",
            "The training loss for state is: 0.03793178126215935\n",
            "The training loss for state is: 0.013039631769061089\n",
            "The training loss for state is: 0.009766669943928719\n",
            "The training loss for state is: 0.027032271027565002\n",
            "The training loss for state is: 0.05630012974143028\n",
            "\u001b[94mAfter 35 epochs the validation total loss is: 0.0222606398165226\u001b[0m\n",
            "\u001b[94mAfter 35 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 35 epochs the validation state loss is: 0.0222606398165226\u001b[0m\n",
            "Epoch 36/50\n",
            "The training loss for state is: 0.024946995079517365\n",
            "The training loss for state is: 0.00929737277328968\n",
            "The training loss for state is: 0.06491231173276901\n",
            "The training loss for state is: 0.017104458063840866\n",
            "The training loss for state is: 0.022904841229319572\n",
            "The training loss for state is: 0.007533500902354717\n",
            "The training loss for state is: 0.007774037308990955\n",
            "The training loss for state is: 0.00860186293721199\n",
            "The training loss for state is: 0.011776205152273178\n",
            "The training loss for state is: 0.05871151015162468\n",
            "The training loss for state is: 0.010485030710697174\n",
            "The training loss for state is: 0.004713311791419983\n",
            "\u001b[94mAfter 36 epochs the validation total loss is: 0.013795643113553524\u001b[0m\n",
            "\u001b[94mAfter 36 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 36 epochs the validation state loss is: 0.013795643113553524\u001b[0m\n",
            "Epoch 37/50\n",
            "The training loss for state is: 0.019537124782800674\n",
            "The training loss for state is: 0.0054518068209290504\n",
            "The training loss for state is: 0.011283591389656067\n",
            "The training loss for state is: 0.00931060966104269\n",
            "The training loss for state is: 0.012083355337381363\n",
            "The training loss for state is: 0.01280113123357296\n",
            "The training loss for state is: 0.011243969202041626\n",
            "The training loss for state is: 0.015637191012501717\n",
            "The training loss for state is: 0.00538224633783102\n",
            "The training loss for state is: 0.006777352653443813\n",
            "The training loss for state is: 0.021724866703152657\n",
            "The training loss for state is: 0.0067311739549040794\n",
            "\u001b[94mAfter 37 epochs the validation total loss is: 0.025985727086663246\u001b[0m\n",
            "\u001b[94mAfter 37 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 37 epochs the validation state loss is: 0.025985727086663246\u001b[0m\n",
            "Epoch 38/50\n",
            "The training loss for state is: 0.007949912920594215\n",
            "The training loss for state is: 0.07361338287591934\n",
            "The training loss for state is: 0.08173616230487823\n",
            "The training loss for state is: 0.006754762958735228\n",
            "The training loss for state is: 0.011969572864472866\n",
            "The training loss for state is: 0.02099449560046196\n",
            "The training loss for state is: 0.028296761214733124\n",
            "The training loss for state is: 0.010571240447461605\n",
            "The training loss for state is: 0.005965360440313816\n",
            "The training loss for state is: 0.007110669277608395\n",
            "The training loss for state is: 0.008037126623094082\n",
            "The training loss for state is: 0.0525214821100235\n",
            "The training loss for state is: 0.013314704410731792\n",
            "\u001b[94mAfter 38 epochs the validation total loss is: 0.03175270929932594\u001b[0m\n",
            "\u001b[94mAfter 38 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 38 epochs the validation state loss is: 0.03175270929932594\u001b[0m\n",
            "Epoch 39/50\n",
            "The training loss for state is: 0.005952226929366589\n",
            "The training loss for state is: 0.013122603297233582\n",
            "The training loss for state is: 0.017009956762194633\n",
            "The training loss for state is: 0.009812205098569393\n",
            "The training loss for state is: 0.02473183535039425\n",
            "The training loss for state is: 0.017898261547088623\n",
            "The training loss for state is: 0.01755315251648426\n",
            "The training loss for state is: 0.00503378314897418\n",
            "The training loss for state is: 0.007617020979523659\n",
            "The training loss for state is: 0.006147688254714012\n",
            "The training loss for state is: 0.017175570130348206\n",
            "The training loss for state is: 0.009991521947085857\n",
            "\u001b[94mAfter 39 epochs the validation total loss is: 0.02922961302101612\u001b[0m\n",
            "\u001b[94mAfter 39 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 39 epochs the validation state loss is: 0.02922961302101612\u001b[0m\n",
            "Epoch 40/50\n",
            "The training loss for state is: 0.0747867226600647\n",
            "The training loss for state is: 0.018126018345355988\n",
            "The training loss for state is: 0.022730551660060883\n",
            "The training loss for state is: 0.05864878371357918\n",
            "The training loss for state is: 0.012130187824368477\n",
            "The training loss for state is: 0.017103316262364388\n",
            "The training loss for state is: 0.010432541370391846\n",
            "The training loss for state is: 0.011031612753868103\n",
            "The training loss for state is: 0.009001672267913818\n",
            "The training loss for state is: 0.0165226049721241\n",
            "The training loss for state is: 0.01314984355121851\n",
            "The training loss for state is: 0.010001312009990215\n",
            "\u001b[94mAfter 40 epochs the validation total loss is: 0.01685181073844433\u001b[0m\n",
            "\u001b[94mAfter 40 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 40 epochs the validation state loss is: 0.01685181073844433\u001b[0m\n",
            "Epoch 41/50\n",
            "The training loss for state is: 0.0055501414462924\n",
            "The training loss for state is: 0.007818195968866348\n",
            "The training loss for state is: 0.06849511712789536\n",
            "The training loss for state is: 0.01045255921781063\n",
            "The training loss for state is: 0.007981076836585999\n",
            "The training loss for state is: 0.009014047682285309\n",
            "The training loss for state is: 0.009702298790216446\n",
            "The training loss for state is: 0.025646189227700233\n",
            "The training loss for state is: 0.010151857510209084\n",
            "The training loss for state is: 0.009317377582192421\n",
            "The training loss for state is: 0.007613385561853647\n",
            "The training loss for state is: 0.008078851737082005\n",
            "\u001b[94mAfter 41 epochs the validation total loss is: 0.05333513393998146\u001b[0m\n",
            "\u001b[94mAfter 41 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 41 epochs the validation state loss is: 0.05333513393998146\u001b[0m\n",
            "Epoch 42/50\n",
            "The training loss for state is: 0.023190725594758987\n",
            "The training loss for state is: 0.0071962750516831875\n",
            "The training loss for state is: 0.058052003383636475\n",
            "The training loss for state is: 0.0062163155525922775\n",
            "The training loss for state is: 0.009653087705373764\n",
            "The training loss for state is: 0.0073870206251740456\n",
            "The training loss for state is: 0.022058788686990738\n",
            "The training loss for state is: 0.02271001599729061\n",
            "The training loss for state is: 0.0227827038615942\n",
            "The training loss for state is: 0.007273075636476278\n",
            "The training loss for state is: 0.06868081539869308\n",
            "The training loss for state is: 0.006426256150007248\n",
            "The training loss for state is: 0.00984094850718975\n",
            "\u001b[94mAfter 42 epochs the validation total loss is: 0.020092923194169998\u001b[0m\n",
            "\u001b[94mAfter 42 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 42 epochs the validation state loss is: 0.020092923194169998\u001b[0m\n",
            "Epoch 43/50\n",
            "The training loss for state is: 0.008715510368347168\n",
            "The training loss for state is: 0.005464613437652588\n",
            "The training loss for state is: 0.03180340677499771\n",
            "The training loss for state is: 0.016308434307575226\n",
            "The training loss for state is: 0.01807156205177307\n",
            "The training loss for state is: 0.031675517559051514\n",
            "The training loss for state is: 0.009122038260102272\n",
            "The training loss for state is: 0.019598931074142456\n",
            "The training loss for state is: 0.01629256084561348\n",
            "The training loss for state is: 0.008972452953457832\n",
            "The training loss for state is: 0.010406813584268093\n",
            "The training loss for state is: 0.03927965089678764\n",
            "\u001b[94mAfter 43 epochs the validation total loss is: 0.014785710722208023\u001b[0m\n",
            "\u001b[94mAfter 43 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 43 epochs the validation state loss is: 0.014785710722208023\u001b[0m\n",
            "Epoch 44/50\n",
            "The training loss for state is: 0.006747928913682699\n",
            "The training loss for state is: 0.008988436311483383\n",
            "The training loss for state is: 0.015394367277622223\n",
            "The training loss for state is: 0.006862429901957512\n",
            "The training loss for state is: 0.005197657272219658\n",
            "The training loss for state is: 0.07722769677639008\n",
            "The training loss for state is: 0.014437365345656872\n",
            "The training loss for state is: 0.01440969854593277\n",
            "The training loss for state is: 0.01304752379655838\n",
            "The training loss for state is: 0.01056382991373539\n",
            "The training loss for state is: 0.05617901682853699\n",
            "The training loss for state is: 0.007847956381738186\n",
            "\u001b[94mAfter 44 epochs the validation total loss is: 0.038175348192453384\u001b[0m\n",
            "\u001b[94mAfter 44 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 44 epochs the validation state loss is: 0.038175348192453384\u001b[0m\n",
            "Epoch 45/50\n",
            "The training loss for state is: 0.017082631587982178\n",
            "The training loss for state is: 0.00815105251967907\n",
            "The training loss for state is: 0.014654689468443394\n",
            "The training loss for state is: 0.00908584427088499\n",
            "The training loss for state is: 0.012071803212165833\n",
            "The training loss for state is: 0.005316144786775112\n",
            "The training loss for state is: 0.022334177047014236\n",
            "The training loss for state is: 0.007108605001121759\n",
            "The training loss for state is: 0.06058819964528084\n",
            "The training loss for state is: 0.05782363936305046\n",
            "The training loss for state is: 0.05354445427656174\n",
            "The training loss for state is: 0.005238724872469902\n",
            "The training loss for state is: 0.007514182943850756\n",
            "\u001b[94mAfter 45 epochs the validation total loss is: 0.01970006339251995\u001b[0m\n",
            "\u001b[94mAfter 45 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 45 epochs the validation state loss is: 0.01970006339251995\u001b[0m\n",
            "Epoch 46/50\n",
            "The training loss for state is: 0.006147220730781555\n",
            "The training loss for state is: 0.0060017304494977\n",
            "The training loss for state is: 0.060628727078437805\n",
            "The training loss for state is: 0.06620381027460098\n",
            "The training loss for state is: 0.00930444523692131\n",
            "The training loss for state is: 0.010346690192818642\n",
            "The training loss for state is: 0.0068685938604176044\n",
            "The training loss for state is: 0.014901038259267807\n",
            "The training loss for state is: 0.06113622710108757\n",
            "The training loss for state is: 0.008276106789708138\n",
            "The training loss for state is: 0.013284329324960709\n",
            "The training loss for state is: 0.0038210321217775345\n",
            "\u001b[94mAfter 46 epochs the validation total loss is: 0.014772089198231697\u001b[0m\n",
            "\u001b[94mAfter 46 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 46 epochs the validation state loss is: 0.014772089198231697\u001b[0m\n",
            "Epoch 47/50\n",
            "The training loss for state is: 0.009919140487909317\n",
            "The training loss for state is: 0.008295536041259766\n",
            "The training loss for state is: 0.005259786732494831\n",
            "The training loss for state is: 0.009628556668758392\n",
            "The training loss for state is: 0.01565210148692131\n",
            "The training loss for state is: 0.010082323104143143\n",
            "The training loss for state is: 0.015519315376877785\n",
            "The training loss for state is: 0.013311969116330147\n",
            "The training loss for state is: 0.003985959105193615\n",
            "The training loss for state is: 0.004945776890963316\n",
            "The training loss for state is: 0.014473534189164639\n",
            "The training loss for state is: 0.006016145925968885\n",
            "\u001b[94mAfter 47 epochs the validation total loss is: 0.029319843277335167\u001b[0m\n",
            "\u001b[94mAfter 47 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 47 epochs the validation state loss is: 0.029319843277335167\u001b[0m\n",
            "Epoch 48/50\n",
            "The training loss for state is: 0.009497001767158508\n",
            "The training loss for state is: 0.008180975914001465\n",
            "The training loss for state is: 0.006221887655556202\n",
            "The training loss for state is: 0.007311202120035887\n",
            "The training loss for state is: 0.008765263482928276\n",
            "The training loss for state is: 0.006710304878652096\n",
            "The training loss for state is: 0.007254616357386112\n",
            "The training loss for state is: 0.00935912411659956\n",
            "The training loss for state is: 0.006657189689576626\n",
            "The training loss for state is: 0.01680334284901619\n",
            "The training loss for state is: 0.009626956656575203\n",
            "The training loss for state is: 0.059135496616363525\n",
            "The training loss for state is: 0.011079306714236736\n",
            "\u001b[94mAfter 48 epochs the validation total loss is: 0.015093784779310226\u001b[0m\n",
            "\u001b[94mAfter 48 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 48 epochs the validation state loss is: 0.015093784779310226\u001b[0m\n",
            "Epoch 49/50\n",
            "The training loss for state is: 0.0116876270622015\n",
            "The training loss for state is: 0.010858968831598759\n",
            "The training loss for state is: 0.008390656672418118\n",
            "The training loss for state is: 0.0170750692486763\n",
            "The training loss for state is: 0.008786603808403015\n",
            "The training loss for state is: 0.006137325428426266\n",
            "The training loss for state is: 0.006746535189449787\n",
            "The training loss for state is: 0.04465199634432793\n",
            "The training loss for state is: 0.00563850486651063\n",
            "The training loss for state is: 0.009498778730630875\n",
            "The training loss for state is: 0.031146157532930374\n",
            "The training loss for state is: 0.0078036366030573845\n",
            "\u001b[94mAfter 49 epochs the validation total loss is: 0.04759017005562782\u001b[0m\n",
            "\u001b[94mAfter 49 epochs the validation mat loss is: 0.0\u001b[0m\n",
            "\u001b[94mAfter 49 epochs the validation state loss is: 0.04759017005562782\u001b[0m\n",
            "predicitng\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /home/dominique/Schreibtisch/JacobianTask/NeuralModel/3/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9omgdHTL4D",
        "colab_type": "text"
      },
      "source": [
        "# Visualization of result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK9qWgmrTgVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_car_state_action",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominique-nshimyimana/Karat-GC/blob/master/lstm_car_state_action.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nPDc8yQtVxk4"
      },
      "source": [
        "#Colab: TensorFlow and GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NeWVBhf1VxlH",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "edd63d01-7b41-48a9-c9f7-3066dee52bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "mounted = '/drive'\n",
        "drive.mount(mounted)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQaNEw6OKZn",
        "colab_type": "text"
      },
      "source": [
        "# NN state Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQXBfd9dOgPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, LSTM, SimpleRNN, GRU, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "\n",
        "def createCarStateActionLSTM((look_back, XS_shape[-1]), y_shape[-1]):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units = 100, return_sequences = True, activation='relu',input_shape=(look_back, XS_shape[-1])))\n",
        "    model.add(LSTM(units = 200, return_sequences = True, activation='relu'))\n",
        "    model.add(LSTM(units = 24, dropout = 0.2, activation='relu', return_sequences=True))\n",
        "    model.add(LSTM(units = 21, dropout = 0.2, activation='relu', return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(units = y_shape[-1], activation='linear')))\n",
        "    return model\n",
        "\n",
        "\n",
        "class CarStateActionLSTM(tf.keras.Model):\n",
        "  '''\n",
        "    # Add a LSTM layer with 128 internal units.\n",
        "    model.add(LSTM(128))\n",
        "    # The output of GRU will be a 3D tensor of shape (batch_size, timesteps, units)\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "    # The output of SimpleRNN will be a 2D tensor of shape (batch_size, units)\n",
        "    model.add(SimpleRNN(128))\n",
        "  '''\n",
        "  def __init__(self, input_shape, output_shape, dropout = False):\n",
        "\n",
        "    super(CarStateActionLSTM, self).__init__()\n",
        "    self.in_shape = input_shape\n",
        "    self.out_shape = output_shape\n",
        "    self.dropout = dropout\n",
        "    \n",
        "    self.model = Sequential()\n",
        "    self.model.add(LSTM(units = np.prod(self.in_shape), return_sequences = True, activation='relu'))\n",
        "    self.model.add(LSTM(units = self.out_shape*np.prod(self.input_shape), return_sequences = True, activation='relu'))\n",
        "    self.model.add(LSTM(units = self.out_shape*4, dropout = 0.2, activation='relu', return_sequences = True))\n",
        "    self.model.add(LSTM(units = self.out_shape*2, dropout = 0.2, activation='relu', return_sequences = True))\n",
        "    self.model.add(TimeDistributed(Dense(units = self.output_shape, activation='linear')))\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    x = tf.nn.dropout(inputs, rate=self.dropout)\n",
        "    return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXEqk8av9as",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0NgTWO5fXnn",
        "colab_type": "text"
      },
      "source": [
        "### Data Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re0CNZtgfFrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dat from folder\n",
        "# CSV form: Dataset\n",
        "# Timestamp, x, y, yaw, xvel, yvel, omega, accel, brake, steering\n",
        "def load_states_actions(data_dir, cutoff_beginning = 300, cutoff_end = 1000, norm=True):\n",
        "  data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) and \".directory\" not in f]\n",
        "\n",
        "  xs_states = []\n",
        "  xs_actions = []\n",
        "  ys = []\n",
        "\n",
        "  for f in data_files:\n",
        "      print(f)\n",
        "      data = np.loadtxt(f, delimiter=', ', skiprows=1, dtype=np.float32)[cutoff_beginning:-cutoff_end, :]\n",
        "      x_states = [data[i, 1:-3] for i in range(len(data))]\n",
        "      x_actions = [data[i, -3:] for i in range(len(data))]\n",
        "      y = x_states[1:]\n",
        "      x_states, x_actions = x_states[:-1], x_actions[:-1]\n",
        "      xs_states += x_states\n",
        "      xs_actions += x_actions\n",
        "\n",
        "  xs_states = np.vstack(xs_states)\n",
        "  xs_actions = np.vstack(xs_actions)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  xs_states = scaler.fit_transform(xs_states)\n",
        "  xs_actions = scaler.fit_transform(xs_actions)\n",
        "  return xs_states, xs_actions\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "# State(s) at a given time t (or time series until t) and Y is the state at the next time (t + 1).\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\tdataX.append(np.squeeze(dataset[i:(i+look_back)])) #dataset[i:(i+look_back), 0]\n",
        "\t\tdataY.append(dataset[i + look_back]) #dataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnG_bIjgfSPg",
        "colab_type": "text"
      },
      "source": [
        "### Load and Preapre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NbVLTb8v7qv",
        "colab_type": "code",
        "outputId": "f4b37f84-070b-4517-b769-728b7b9b26ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load Data\n",
        "data_dir = \"/drive/My Drive/neuronyte_logging\"\n",
        "xs_states, xs_actions = load_states_actions(data_dir=data_dir)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585748620.316643\n",
            "/drive/My Drive/neuronyte_logging/NeuroNyte_1585745385.311904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ8S9xVOjobF",
        "colab_type": "code",
        "outputId": "48242258-70a2-4f3a-cadc-d9cfdac83e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Split data\n",
        "x_states_train, x_states_test, x_actions_train, x_actions_test = train_test_split(xs_states, xs_actions, test_size=0.10)\n",
        "\n",
        "# How many steps/state in back from t and # How many steps/state in future/forward from t\n",
        "look_back = 10\n",
        "look_forward = 1\n",
        "\n",
        "# reshape into X=t and Y=t+1 for states\n",
        "x_states_train, y_train = create_dataset(x_states_train, look_back)\n",
        "x_states_test, y_test = create_dataset(x_states_test, look_back)\n",
        "\n",
        "# Size\n",
        "print(x_states_train.shape, x_actions_train.shape, y_train.shape)\n",
        "print(x_states_test.shape, x_actions_test.shape, y_test.shape)\n",
        "\n",
        "# Visualize X=t and Y=t+1\n",
        "t = 3\n",
        "print(y_test[t])\n",
        "print(x_states_test[t+1])\n",
        "\n",
        "XS_shape, XA_shape, y_shape = x_states_train.shape, x_actions_train.shape, y_train.shape\n",
        "X = np.array(x_states_train).reshape(XS_shape[0], look_back, XS_shape[-1])\n",
        "Y = np.array(y_train).reshape(y_shape[0], look_forward, y_shape[-1])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(948071, 10, 6) (948082, 3) (948071, 6)\n",
            "(105332, 10, 6) (105343, 3) (105332, 6)\n",
            "[0.37424535 0.13924694 0.7270725  0.7409239  0.5350734  0.49997193]\n",
            "[[0.05207235 0.23790044 0.94030714 0.60957265 0.15868369 0.5006329 ]\n",
            " [0.75319105 0.18277627 0.13920838 0.45517683 0.46346644 0.4999416 ]\n",
            " [0.6460107  0.05012929 0.24931204 0.00763676 0.49099526 0.49997658]\n",
            " [0.9517953  0.39264026 0.02845061 0.41546392 0.04266897 0.49989057]\n",
            " [0.8439419  0.11120158 0.7106651  0.9785719  0.6029468  0.5003241 ]\n",
            " [0.4543416  0.28463978 0.23745495 0.3281563  0.4864741  0.49997187]\n",
            " [0.20290941 0.19910985 0.55314004 0.57617784 0.7438341  0.49931416]\n",
            " [0.674147   0.5118116  0.935324   0.56995326 0.23333722 0.5005042 ]\n",
            " [0.07806629 0.4379715  0.48367113 0.4736774  0.83786714 0.50003844]\n",
            " [0.37424535 0.13924694 0.7270725  0.7409239  0.5350734  0.49997193]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHG-kUgxvoZD",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ur1DL7vljj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1a2102d8-33b3-4a6b-f370-5f9adf0a08b2"
      },
      "source": [
        "decay=tf.keras.optimizers.schedules.ExponentialDecay(0.0004, 20000, 0.99)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=decay)\n",
        "\n",
        "print((look_back, XS_shape[-1]))\n",
        "#model = CarStateActionLSTM((look_back, XS_shape[-1]), y_shape[-1])\n",
        "model = createCarStateActionLSTM((look_back, XS_shape[-1]), y_shape[-1])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 6)\n",
            "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_72 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mCDvJ1evPe2",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS5aNB28pkbW",
        "colab_type": "code",
        "outputId": "55f8ce6c-1684-4dae-e5eb-891d46b7a6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(x_states_train.shape, x_actions_train.shape, y_train.shape)\n",
        "EPOCHS = 100\n",
        "model.compile(optimizer = optimizer, loss='mse')\n",
        "\n",
        "# checkpoint\n",
        "'''\n",
        "filepath=join(mounted, \"My Drive/NeuralModel/lstm_car_state/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "# Fit the model\n",
        "history = model.fit(X, Y, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=20000, callbacks=callbacks_list)\n",
        "'''\n",
        "\n",
        "history = model.fit(X, Y, epochs=EPOCHS, validation_split=0.2, verbose=1, batch_size=2000)\n",
        "model.save(join(mounted, 'My Drive/NeuralModel/lstm_car_state/lstm_fin.h5'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(948071, 10, 6) (948082, 3) (948071, 6)\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 36s 95ms/step - loss: 0.0876 - val_loss: 0.0512\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0512 - val_loss: 0.0506\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0508 - val_loss: 0.0506\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0507 - val_loss: 0.0506\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0506 - val_loss: 0.0505\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0506 - val_loss: 0.0506\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0506 - val_loss: 0.0505\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 36s 93ms/step - loss: 0.0506 - val_loss: 0.0506\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 35s 91ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 35s 91ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0506\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 35s 91ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 36s 96ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 36s 95ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0506\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 35s 91ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 36s 94ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 34s 91ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 36s 95ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 36s 95ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 35s 93ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 35s 92ms/step - loss: 0.0505 - val_loss: 0.0505\n",
            "Epoch 51/100\n",
            "160/380 [===========>..................] - ETA: 19s - loss: 0.0505"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm4Kgzn-0RUh",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri_jQRJ10Qcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_states_test.shape, x_actions_test.shape, y_test.shape)\n",
        "test_input = x_states_train[11121:11126]\n",
        "test_input = test_input.reshape((test_input.shape[0], 1, test_input.shape[1]))\n",
        "\n",
        "test_output = model.predict(test_input, verbose=0)\n",
        "print(test_output.shape, 'OUT Shape')\n",
        "print(test_input.shape, 'IN Shape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGjDlTRoOsT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for zx in zip(test_input[:, :, :2],test_output[:, :, :2]):\n",
        "  print(zx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9omgdHTL4D",
        "colab_type": "text"
      },
      "source": [
        "# Visualization of result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK9qWgmrTgVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x, y, ... from shape=(6,)\n",
        "xs_states_inpt = np.squeeze(test_input[:, :, :2])\n",
        "xs_states_pred = np.squeeze(test_output[:, :, :2])\n",
        "\n",
        "plt.plot(*zip(*xs_states_inpt), 'r')\n",
        "plt.plot(*zip(*xs_states_pred),'b')\n",
        "plt.xlabel('x pos')\n",
        "plt.ylabel('y pos')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "786CRJ9yWkDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nice to look at\n",
        "!pip install gym\n",
        "import gym\n",
        "env = gym.make('CartPole-v0')\n",
        "env.reset()\n",
        "for _ in range(1000):\n",
        "    #env.render()\n",
        "    env.step(env.action_space.sample()) # take a random action\n",
        "env.close()\n",
        "help(env.__doc__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZGtRT-46agU",
        "colab_type": "text"
      },
      "source": [
        "## Docs\n",
        "\n",
        "\n",
        "1.   https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "2.   https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/\n",
        "3.   https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c\n",
        "4.   https://keras.io/guides/functional_api/,  https://keras.io/api/models/model/ and https://keras.io/api/layers/recurrent_layers/\n",
        "\n"
      ]
    }
  ]
}